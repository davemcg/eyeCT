---
title: "Build and Apply a Human Brain Region Predictor in 60 seconds or less"
output: rmarkdown::html_vignette
date: "2023-07-25"
vignette: >
  %\VignetteIndexEntry{Build and Apply a Human Brain Region Predictor in 60 seconds or less}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---



# Introduction
The GTEx resource contains thousands of human RNA-seq tissues. Here we use the recount3 package
to pull the GTEx brain RNA-seq datasets, use a subset to build a brain region predictor, then apply it
to the remaining GTEx brain data **and** bring in a *outside* human brain study to see whether the
model still is useful.


# Pull in GTEx brain counts via recount3
This is the longest step in this vignette. Takes me about 10-20 seconds, though your time will vary depending on the vagaries of the internet.

We show the `gtex.smtsd` to see the brain regions assayed in GTEx.

```{r}
library(ggplot2)
library(dplyr)
library(recount3)
# library(metamoRph)
human_projects <- available_projects()

project_info <- subset(human_projects, file_source == "gtex" & project_type == "data_sources" &
    project == "BRAIN")

rse_gene_brain <- create_rse(project_info)

colData(rse_gene_brain)$gtex.sex %>%
    table()
```


# Extract read counts


```{r}
brain_counts <- compute_read_counts(rse_gene_brain)
```

# Build metadata table for the "train" and "project" data
The `train` data is used to build the PCA object. That PCA data is used in the model building. The `project` data is then morphed/projected onto the PCA space with `metamoRph` and the output from that is used by `model_apply` to guess the tissue label.

This all happens in less than 10 seconds on my MacBook.

I find (anecdotally) that using a fairly large number of PC (200 in this case) tends
to have modestly label transfer performance with bulk RNA seq data.

```{r}
set.seed(20230824)
train_meta <- colData(rse_gene_brain) %>%
    as_tibble(rownames = "id") %>%
    group_by(gtex.smtsd) %>%
    sample_n(40)
project_meta <- colData(rse_gene_brain) %>%
    as_tibble(rownames = "id") %>%
    filter(!id %in% train_meta$id)

train_counts <- brain_counts[, train_meta$id]
project_counts <- brain_counts[, project_meta$id]

gtex_pca <- run_pca(train_counts, train_meta)

trained_model <- model_build(gtex_pca$PCA$x, gtex_pca$meta %>%
    pull(gtex.smtsd), num_PCs = 200, verbose = FALSE)

projected_data <- metamoRph(project_counts, gtex_pca$PCA$rotation, gtex_pca$center_scale)
# apply model
label_guesses <- model_apply(trained_model, projected_data, project_meta %>%
    pull(gtex.smtsd))
```
# Accuracy

```{r}
num_correct <- label_guesses %>%
    filter(sample_label == predict) %>%
    nrow()
num_wrong <- label_guesses %>%
    filter(sample_label != predict) %>%
    nrow()

# accuracy
num_correct/(num_correct + num_wrong)
```

# Visualizing the label outcomes on the PC
You can see how in many of the "misablels" are on the edge (or further!) of the groups.

```{r}
bind_rows(projected_data %>%
    as_tibble(rownames = "id")) %>%
    left_join(colData(rse_gene_brain) %>%
        as_tibble(rownames = "id"), by = "id") %>%
    left_join(label_guesses, by = c(id = "sample_id")) %>%
    mutate(correct = case_when(sample_label == predict ~ "Yes", TRUE ~ "No")) %>%
    ggplot(aes(x = PC1, y = PC2, color = correct)) + geom_point(alpha = 0.5) + cowplot::theme_cowplot() +
    facet_wrap(~gtex.smtsd)
```


# Now a harder thing - using **outside** data on the model we built
BA9 prefontal cortex - and the model built still has ~89% accuracy.

```{r}
# outside brain prefrontal cortex (BA9)
outside_gtex <- subset(human_projects, project_type == "data_sources" & project == "SRP058181")
rse_gene_outside <- create_rse(outside_gtex)

outside_counts <- compute_read_counts(rse_gene_outside)
outside_meta <- colData(rse_gene_outside) %>%
    as_tibble(rownames = "id")
outside_counts <- outside_counts[, outside_meta$id]


projected_data_outside <- metamoRph(outside_counts, gtex_pca$PCA$rotation, gtex_pca$center_scale)
label_guesses_outside <- model_apply(trained_model, projected_data_outside)
```

## Accuracy

```{r}
num_correct <- label_guesses_outside %>%
    filter(grepl("BA9", predict)) %>%
    nrow()
num_wrong <- label_guesses_outside %>%
    filter(!grepl("BA9", predict)) %>%
    nrow()

# accuracy
num_correct/(num_correct + num_wrong)
#> [1] 0.8767123
```

# Session Info

```{r}
sessionInfo()
```
